{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model by preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-23 19:16:38.166626: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-23 19:16:38.413250: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-01-23 19:16:40.733067: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/dahala/miniconda3/envs/dlashok/lib/\n",
      "2023-01-23 19:16:40.733174: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/dahala/miniconda3/envs/dlashok/lib/\n",
      "2023-01-23 19:16:40.733185: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdahal\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/dahala/extremevaluelandslides/wandb/run-20230123_191651-kmk2txpo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dahal/Extreme%20Value/runs/kmk2txpo\" target=\"_blank\">laced-capybara-26</a></strong> to <a href=\"https://wandb.ai/dahal/Extreme%20Value\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow as tf\n",
    "import json\n",
    "from src import preparedata\n",
    "from src import modelarea\n",
    "from src import trainarea\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices(\n",
    "    device_type=None\n",
    "))\n",
    "\n",
    "params=json.load(open('params/params.json','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "323e9e030ea84fa7ae7535018f1e0f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#prepare data\n",
    "dataset=preparedata.readGPDData(params['dataprepinargs'])\n",
    "dataset.preparedata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-23 19:18:10.499196: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-23 19:18:11.040056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10404 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:b2:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "#prepare model\n",
    "landslidehazard=modelarea.lhmodel(params['modelparam'])\n",
    "landslidehazard.preparemodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1787/1790 [============================>.] - ETA: 0s - loss: -12462310.0000 - gpdmetric: 4481710.0000\n",
      "Epoch 1: val_loss improved from inf to -15031245.00000, saving model to checkpoints/\n",
      "INFO:tensorflow:Assets written to: checkpoints/assets\n",
      "1790/1790 [==============================] - 25s 13ms/step - loss: -12463429.0000 - gpdmetric: 4481012.0000 - val_loss: -15031245.0000 - val_gpdmetric: 5299944.5000\n",
      "Epoch 2/20\n",
      "1789/1790 [============================>.] - ETA: 0s - loss: -15824234.0000 - gpdmetric: 5800638.5000\n",
      "Epoch 2: val_loss improved from -15031245.00000 to -15909166.00000, saving model to checkpoints/\n",
      "INFO:tensorflow:Assets written to: checkpoints/assets\n",
      "1790/1790 [==============================] - 23s 13ms/step - loss: -15821153.0000 - gpdmetric: 5797993.5000 - val_loss: -15909166.0000 - val_gpdmetric: 5822623.0000\n",
      "Epoch 3/20\n",
      "1790/1790 [==============================] - ETA: 0s - loss: -16103245.0000 - gpdmetric: 5960246.0000\n",
      "Epoch 3: val_loss improved from -15909166.00000 to -16131786.00000, saving model to checkpoints/\n",
      "INFO:tensorflow:Assets written to: checkpoints/assets\n",
      "1790/1790 [==============================] - 23s 13ms/step - loss: -16103245.0000 - gpdmetric: 5960246.0000 - val_loss: -16131786.0000 - val_gpdmetric: 5961705.5000\n",
      "Epoch 4/20\n",
      "1790/1790 [==============================] - ETA: 0s - loss: -16184235.0000 - gpdmetric: 6005196.5000\n",
      "Epoch 4: val_loss improved from -16131786.00000 to -16206659.00000, saving model to checkpoints/\n",
      "INFO:tensorflow:Assets written to: checkpoints/assets\n",
      "1790/1790 [==============================] - 23s 13ms/step - loss: -16184235.0000 - gpdmetric: 6005196.5000 - val_loss: -16206659.0000 - val_gpdmetric: 6009495.5000\n",
      "Epoch 5/20\n",
      "1790/1790 [==============================] - ETA: 0s - loss: -16215395.0000 - gpdmetric: 6021025.5000\n",
      "Epoch 5: val_loss improved from -16206659.00000 to -16230183.00000, saving model to checkpoints/\n",
      "INFO:tensorflow:Assets written to: checkpoints/assets\n",
      "1790/1790 [==============================] - 23s 13ms/step - loss: -16215395.0000 - gpdmetric: 6021025.5000 - val_loss: -16230183.0000 - val_gpdmetric: 6025340.0000\n",
      "Epoch 6/20\n",
      "1789/1790 [============================>.] - ETA: 0s - loss: -16230457.0000 - gpdmetric: 6029781.5000\n",
      "Epoch 6: val_loss improved from -16230183.00000 to -16238103.00000, saving model to checkpoints/\n",
      "INFO:tensorflow:Assets written to: checkpoints/assets\n",
      "1790/1790 [==============================] - 23s 13ms/step - loss: -16227303.0000 - gpdmetric: 6027020.5000 - val_loss: -16238103.0000 - val_gpdmetric: 6030572.5000\n",
      "Epoch 7/20\n",
      "1790/1790 [==============================] - ETA: 0s - loss: -16231910.0000 - gpdmetric: 6029319.5000\n",
      "Epoch 7: val_loss improved from -16238103.00000 to -16240729.00000, saving model to checkpoints/\n",
      "INFO:tensorflow:Assets written to: checkpoints/assets\n",
      "1790/1790 [==============================] - 23s 13ms/step - loss: -16231910.0000 - gpdmetric: 6029319.5000 - val_loss: -16240729.0000 - val_gpdmetric: 6032346.0000\n",
      "Epoch 8/20\n",
      "1790/1790 [==============================] - ETA: 0s - loss: -16233662.0000 - gpdmetric: 6030202.5000\n",
      "Epoch 8: val_loss improved from -16240729.00000 to -16241788.00000, saving model to checkpoints/\n",
      "INFO:tensorflow:Assets written to: checkpoints/assets\n",
      "1790/1790 [==============================] - 23s 13ms/step - loss: -16233662.0000 - gpdmetric: 6030202.5000 - val_loss: -16241788.0000 - val_gpdmetric: 6032776.0000\n",
      "Epoch 9/20\n",
      "1790/1790 [==============================] - ETA: 0s - loss: -16234336.0000 - gpdmetric: 6030553.5000\n",
      "Epoch 9: val_loss improved from -16241788.00000 to -16241986.00000, saving model to checkpoints/\n",
      "INFO:tensorflow:Assets written to: checkpoints/assets\n",
      "1790/1790 [==============================] - 22s 12ms/step - loss: -16234336.0000 - gpdmetric: 6030553.5000 - val_loss: -16241986.0000 - val_gpdmetric: 6032926.5000\n",
      "Epoch 10/20\n",
      "1790/1790 [==============================] - ETA: 0s - loss: -16234665.0000 - gpdmetric: 6030689.5000\n",
      "Epoch 10: val_loss did not improve from -16241986.00000\n",
      "1790/1790 [==============================] - 19s 11ms/step - loss: -16234665.0000 - gpdmetric: 6030689.5000 - val_loss: -16241764.0000 - val_gpdmetric: 6033025.0000\n",
      "Epoch 11/20\n",
      "1790/1790 [==============================] - ETA: 0s - loss: -16235019.0000 - gpdmetric: 6030773.5000\n",
      "Epoch 11: val_loss did not improve from -16241986.00000\n",
      "1790/1790 [==============================] - 19s 11ms/step - loss: -16235019.0000 - gpdmetric: 6030773.5000 - val_loss: -16241771.0000 - val_gpdmetric: 6033043.0000\n",
      "Epoch 12/20\n",
      "1788/1790 [============================>.] - ETA: 0s - loss: -16238142.0000 - gpdmetric: 6033569.5000\n",
      "Epoch 12: val_loss improved from -16241986.00000 to -16242279.00000, saving model to checkpoints/\n",
      "INFO:tensorflow:Assets written to: checkpoints/assets\n",
      "1790/1790 [==============================] - 23s 13ms/step - loss: -16234957.0000 - gpdmetric: 6030802.0000 - val_loss: -16242279.0000 - val_gpdmetric: 6032948.5000\n",
      "Epoch 13/20\n",
      "1790/1790 [==============================] - ETA: 0s - loss: -16234966.0000 - gpdmetric: 6030798.0000\n",
      "Epoch 13: val_loss did not improve from -16242279.00000\n",
      "1790/1790 [==============================] - 19s 11ms/step - loss: -16234966.0000 - gpdmetric: 6030798.0000 - val_loss: -16241926.0000 - val_gpdmetric: 6033027.0000\n",
      "Epoch 14/20\n",
      "1790/1790 [==============================] - ETA: 0s - loss: -16235040.0000 - gpdmetric: 6030819.0000\n",
      "Epoch 14: val_loss did not improve from -16242279.00000\n",
      "1790/1790 [==============================] - 19s 11ms/step - loss: -16235040.0000 - gpdmetric: 6030819.0000 - val_loss: -16242219.0000 - val_gpdmetric: 6032963.0000\n",
      "Epoch 15/20\n",
      "1788/1790 [============================>.] - ETA: 0s - loss: -16238546.0000 - gpdmetric: 6033596.0000\n",
      "Epoch 15: val_loss did not improve from -16242279.00000\n",
      "1790/1790 [==============================] - 19s 11ms/step - loss: -16235238.0000 - gpdmetric: 6030824.5000 - val_loss: -16241839.0000 - val_gpdmetric: 6033041.0000\n",
      "Epoch 16/20\n",
      "1790/1790 [==============================] - ETA: 0s - loss: -16235206.0000 - gpdmetric: 6030825.5000\n",
      "Epoch 16: val_loss did not improve from -16242279.00000\n",
      "1790/1790 [==============================] - 19s 11ms/step - loss: -16235206.0000 - gpdmetric: 6030825.5000 - val_loss: -16242062.0000 - val_gpdmetric: 6032997.5000\n",
      "Epoch 17/20\n",
      "1790/1790 [==============================] - ETA: 0s - loss: -16235202.0000 - gpdmetric: 6030830.5000\n",
      "Epoch 17: val_loss did not improve from -16242279.00000\n",
      "1790/1790 [==============================] - 19s 11ms/step - loss: -16235202.0000 - gpdmetric: 6030830.5000 - val_loss: -16241431.0000 - val_gpdmetric: 6033107.0000\n",
      "Epoch 18/20\n",
      "1787/1790 [============================>.] - ETA: 0s - loss: -16238552.0000 - gpdmetric: 6033617.0000\n",
      "Epoch 18: val_loss did not improve from -16242279.00000\n",
      "1790/1790 [==============================] - 19s 11ms/step - loss: -16235261.0000 - gpdmetric: 6030837.0000 - val_loss: -16242166.0000 - val_gpdmetric: 6032964.0000\n",
      "Epoch 19/20\n",
      "1785/1790 [============================>.] - ETA: 0s - loss: -16238320.0000 - gpdmetric: 6033583.5000\n",
      "Epoch 19: val_loss did not improve from -16242279.00000\n",
      "1790/1790 [==============================] - 19s 11ms/step - loss: -16235261.0000 - gpdmetric: 6030827.0000 - val_loss: -16242170.0000 - val_gpdmetric: 6032964.0000\n",
      "Epoch 20/20\n",
      "1787/1790 [============================>.] - ETA: 0s - loss: -16238314.0000 - gpdmetric: 6033567.5000\n",
      "Epoch 20: val_loss did not improve from -16242279.00000\n",
      "1790/1790 [==============================] - 19s 11ms/step - loss: -16235273.0000 - gpdmetric: 6030822.5000 - val_loss: -16242222.0000 - val_gpdmetric: 6032939.5000\n"
     ]
    }
   ],
   "source": [
    "trainarea.trainmodel(landslidehazard.model,dataset.X_train,dataset.Y_train,params['trainparam'])\n",
    "landslidehazard.model.save_weights('savedweights/final_modelfull_data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "landslidehazard.model.save_weights('savedweights/final_modelfull_data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'readGPDData' object has no attribute 'X_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m landslidehazard\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mpredict(dataset\u001b[39m.\u001b[39;49mX_train[:\u001b[39m10\u001b[39m,\u001b[39m0\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'readGPDData' object has no attribute 'X_train'"
     ]
    }
   ],
   "source": [
    "landslidehazard.model.predict(dataset.X_train[:10,0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform inference by calculating landslide hazrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "2.10.1\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow as tf\n",
    "import json\n",
    "from src import preparedata\n",
    "from src import modelarea\n",
    "from src import inference\n",
    "from src import savehazard\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices(\n",
    "    device_type=None\n",
    "))\n",
    "params=json.load(open('params/params.json','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e18359d07f4c0093189f4f72262663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rp=20\n",
    "dataset=preparedata.readGPDData(params['dataprepinargs'])\n",
    "dataset.preparedatainference(rp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2219/2219 [==============================] - 4s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "landslidehazard=modelarea.lhmodel(params['modelparam'])\n",
    "landslidehazard.preparemodel()\n",
    "haz=inference.inferenceLH(model=landslidehazard.model,model_weights='savedweights/final_modelfull_data.h5',xdata=dataset.Xinference,rp=rp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "savehazard.save_predicted_Haz(ids=dataset.InferenceID,prediction=haz,hazcol=f'haz_{rp}rp',sufile='Data/SlopeUnits/SlopeUnits_V3.shp',outfile=f'Data/Results/LsHaz{rp}_v2.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22016518"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haz.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11952155"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haz.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17237218046254701"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "np.exp(-1.7580993)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
